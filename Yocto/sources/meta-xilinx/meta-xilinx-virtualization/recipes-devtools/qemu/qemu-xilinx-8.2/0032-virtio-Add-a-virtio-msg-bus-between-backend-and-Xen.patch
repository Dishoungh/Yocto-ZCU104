From c745aa85055071ea6c499114fea3b1c4e9e7a4fc Mon Sep 17 00:00:00 2001
From: "Edgar E. Iglesias" <edgar.iglesias@amd.com>
Date: Wed, 27 Aug 2025 19:25:09 +0200
Subject: [PATCH 32/34] virtio: Add a virtio-msg bus between backend and Xen

Add a virtio-msg bus between backend and Xen. This is for
virtio-msg between the backend and a front-end in Xen itself.

Signed-off-by: Edgar E. Iglesias <edgar.iglesias@amd.com>
Reviewed-by: Stefano Stabellini <stefano.stabellini@amd.com>
---
 hw/virtio/meson.build                  |   3 +
 hw/virtio/virtio-msg-bus-xen.c         | 263 +++++++++++++++++++++++++
 include/hw/virtio/pagemap.h            | 100 ++++++++++
 include/hw/virtio/spsc_queue.h         | 213 ++++++++++++++++++++
 include/hw/virtio/virtio-msg-bus-xen.h |  48 +++++
 5 files changed, 627 insertions(+)
 create mode 100644 hw/virtio/virtio-msg-bus-xen.c
 create mode 100644 include/hw/virtio/pagemap.h
 create mode 100644 include/hw/virtio/spsc_queue.h
 create mode 100644 include/hw/virtio/virtio-msg-bus-xen.h

diff --git a/hw/virtio/meson.build b/hw/virtio/meson.build
index 7ede71ee49..c760343fd5 100644
--- a/hw/virtio/meson.build
+++ b/hw/virtio/meson.build
@@ -16,6 +16,9 @@ specific_virtio_ss.add(when: 'CONFIG_VIRTIO_MSG', if_true: files(
     'virtio-msg-bus.c',
 ))
 
+specific_virtio_ss.add(when: ['CONFIG_VIRTIO_MSG', 'CONFIG_XEN', xen],
+                       if_true: files('virtio-msg-bus-xen.c'))
+
 if have_vhost
   system_virtio_ss.add(files('vhost.c'))
   specific_virtio_ss.add(files('vhost-backend.c', 'vhost-iova-tree.c'))
diff --git a/hw/virtio/virtio-msg-bus-xen.c b/hw/virtio/virtio-msg-bus-xen.c
new file mode 100644
index 0000000000..c5a6ea2a21
--- /dev/null
+++ b/hw/virtio/virtio-msg-bus-xen.c
@@ -0,0 +1,263 @@
+/*
+ * virtio-msg bus on top Xen.
+ *
+ * Uses either grant or foreign mappings for the shared queues.
+ * Uses event channels for notifications both ways.
+ *
+ * Copyright (c) 2024 Advanced Micro Devices, Inc.
+ * Written by Edgar E. Iglesias <edgar.iglesias@amd.com>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#include "qemu/osdep.h"
+#include "qemu/units.h"
+#include "qapi/error.h"
+#include "hw/qdev-properties.h"
+#include "hw/qdev-properties-system.h"
+#include "hw/xen/xen_native.h"
+#include "hw/xen/xen-bus-helper.h"
+
+#include "hw/virtio/virtio-msg-bus-xen.h"
+#include "hw/virtio/pagemap.h"
+
+static void virtio_msg_bus_xen_send_notify(VirtIOMSGBusXen *s)
+{
+    qemu_xen_evtchn_notify(s->xen.eh, s->xen.local_port);
+}
+
+static void virtio_msg_bus_xen_recv(VirtIOMSGBusDevice *bd,
+                                    VirtIOMSG *msg)
+{
+    /* Need to unpack xen bus messages.  */
+    virtio_msg_unpack(msg);
+
+    /* We don't have any bus specific messages.  */
+}
+
+static void virtio_msg_bus_xen_process(VirtIOMSGBusDevice *bd)
+{
+    VirtIOMSGBusXen *s = VIRTIO_MSG_BUS_XEN(bd);
+    spsc_queue *q;
+    VirtIOMSG msg;
+    bool r;
+
+    if (!bd->peer) {
+        return;
+    }
+
+    /*
+     * We process the opposite queue, i.e, a driver will want to receive
+     * messages on the backend queue (and send messages on the driver queue).
+     */
+    q = bd->peer->is_driver ? &s->shm_queues.device : &s->shm_queues.driver;
+    do {
+        r = spsc_recv(q, &msg, sizeof msg);
+        if (r) {
+            if (msg.type & VIRTIO_MSG_TYPE_BUS) {
+                virtio_msg_bus_xen_recv(bd, &msg);
+            } else {
+                virtio_msg_bus_receive(bd, &msg);
+            }
+        }
+    } while (r);
+}
+
+static int virtio_msg_bus_xen_send(VirtIOMSGBusDevice *bd, VirtIOMSG *msg_req)
+{
+    VirtIOMSGBusXen *s = VIRTIO_MSG_BUS_XEN(bd);
+    spsc_queue *q_tx;
+    bool sent;
+
+    q_tx = bd->peer->is_driver ? &s->shm_queues.driver : &s->shm_queues.device;
+
+    /* TODO: Add a way to handle retries. */
+    sent = spsc_send(q_tx, msg_req, sizeof *msg_req);
+
+    if (sent) {
+        virtio_msg_bus_xen_send_notify(s);
+    }
+
+    return sent ? VIRTIO_MSG_NO_ERROR : VIRTIO_MSG_ERROR_RETRY;
+}
+
+static void virtio_msg_bus_xen_event(void *opaque)
+{
+    VirtIOMSGBusXen *s = VIRTIO_MSG_BUS_XEN(opaque);
+    VirtIOMSGBusDevice *bd = VIRTIO_MSG_BUS_DEVICE(opaque);
+    int port;
+
+    port = qemu_xen_evtchn_pending(s->xen.eh);
+    if (port != s->xen.local_port) {
+        return;
+    }
+
+    qemu_xen_evtchn_unmask(s->xen.eh, port);
+    virtio_msg_bus_xen_process(bd);
+}
+
+static bool virtio_msg_bus_xen_connect_evtchn(VirtIOMSGBusXen *s, int port)
+{
+    xenevtchn_port_or_error_t lp;
+    int fd;
+
+    lp = qemu_xen_evtchn_bind_interdomain(s->xen.eh, xen_domid, port);
+    if (lp < 0) {
+        return false;
+    }
+
+    /* Register with main loop.  */
+    fd = qemu_xen_evtchn_fd(s->xen.eh);
+    if (fd < 0) {
+        qemu_xen_evtchn_unbind(s->xen.eh, lp);
+        return false;
+    }
+
+    qemu_set_fd_handler(fd, virtio_msg_bus_xen_event, NULL, s);
+    s->xen.local_port = lp;
+    return true;
+}
+
+static void virtio_msg_bus_xen_connect(VirtIOMSGBusXen *s, Error **errp)
+{
+    uint32_t port = 0;
+    uint64_t gfn;
+    uint64_t pa;
+    void *user_va;
+    int rc;
+
+    /* Map shm page.  */
+    user_va = mmap(NULL, XEN_PAGE_SIZE, PROT_READ | PROT_WRITE,
+                   MAP_ANONYMOUS | MAP_SHARED, -1, 0);
+    if (user_va == MAP_FAILED) {
+        error_setg(errp, "Failed to map shm page");
+        return;
+    }
+
+    /* Pin and populate pages.  */
+    if (mlock(user_va, XEN_PAGE_SIZE) != 0) {
+        warn_report_once("virtio-msg: mlock failed; continuing without pin");
+    }
+    memset(user_va, 0, XEN_PAGE_SIZE);
+
+    pa = pagemap_virt_to_phys(user_va);
+    if (pa == PAGEMAP_FAILED) {
+        error_setg(errp, "Failed to get gfn of shm page");
+        munmap(user_va, XEN_PAGE_SIZE);
+        return;
+    }
+
+    gfn = pa >> XEN_PAGE_SHIFT;
+
+    /* Now connect to the virtio-msg bus.  */
+    rc = xendevicemodel_virtio_msg_bus_xen_connect(xen_dmod, xen_domid,
+                                                   s->cfg.bus_id,
+                                                   s->cfg.dev_num,
+                                                   gfn, &port);
+    if (rc < 0) {
+        error_setg_errno(errp, errno, "virtio-msg-bus-xen: connect failed");
+        munmap(user_va, XEN_PAGE_SIZE);
+        return;
+    }
+
+    /* Done.  */
+    s->xen.shm = user_va;
+    s->xen.port = port;
+}
+
+static void virtio_msg_bus_xen_realize(DeviceState *dev, Error **errp)
+{
+    VirtIOMSGBusXen *s = VIRTIO_MSG_BUS_XEN(dev);
+    VirtIOMSGBusDeviceClass *bdc = VIRTIO_MSG_BUS_DEVICE_GET_CLASS(dev);
+    g_autofree char *name_driver = NULL;
+    g_autofree char *name_device = NULL;
+
+    if (bdc->parent_realize) {
+        bdc->parent_realize(dev, errp);
+        if (*errp) {
+            return;
+        }
+    }
+
+    s->xen.eh = qemu_xen_evtchn_open();
+    if (!s->xen.eh) {
+        error_setg_errno(errp, errno, "failed xenevtchn_open");
+        return;
+    }
+
+    virtio_msg_bus_xen_connect(s, errp);
+    if (*errp) {
+        qemu_xen_evtchn_close(s->xen.eh);
+        return;
+    }
+
+    spsc_init(&s->shm_queues.driver, "driver", spsc_capacity(1 * KiB),
+              s->xen.shm);
+    spsc_init(&s->shm_queues.device, "device", spsc_capacity(1 * KiB),
+              s->xen.shm + 1 * KiB);
+
+    if (!virtio_msg_bus_xen_connect_evtchn(s, s->xen.port)) {
+        error_setg_errno(errp, errno, "Failed to connect to event channel!");
+        qemu_xen_evtchn_close(s->xen.eh);
+        munmap(s->xen.shm, XEN_PAGE_SIZE);
+    }
+}
+
+static void virtio_msg_bus_xen_unrealize(DeviceState *dev)
+{
+    VirtIOMSGBusDeviceClass *bdc = VIRTIO_MSG_BUS_DEVICE_GET_CLASS(dev);
+    VirtIOMSGBusXen *s = VIRTIO_MSG_BUS_XEN(dev);
+    int fd;
+
+    if (bdc->parent_unrealize) {
+        bdc->parent_unrealize(dev);
+    }
+
+    /* Since realize() succeeded, s->xen.eh is valid and needs teardown.  */
+    assert(s->xen.eh);
+    fd = qemu_xen_evtchn_fd(s->xen.eh);
+    if (fd >= 0) {
+        qemu_set_fd_handler(fd, NULL, NULL, NULL);
+    }
+    qemu_xen_evtchn_unbind(s->xen.eh, s->xen.local_port);
+    qemu_xen_evtchn_close(s->xen.eh);
+
+    /* Since realize() succeeded, s->xen.shm needs unmapping.  */
+    assert(s->xen.shm != MAP_FAILED);
+    munmap(s->xen.shm, XEN_PAGE_SIZE);
+}
+
+static Property virtio_msg_bus_xen_props[] = {
+    DEFINE_PROP_UINT32("bus-id", VirtIOMSGBusXen, cfg.bus_id, 0),
+    DEFINE_PROP_UINT16("dev-num", VirtIOMSGBusXen, cfg.dev_num, 0),
+    DEFINE_PROP_END_OF_LIST(),
+};
+
+static void virtio_msg_bus_xen_class_init(ObjectClass *klass, void *data)
+{
+    DeviceClass *dc = DEVICE_CLASS(klass);
+    VirtIOMSGBusDeviceClass *bdc = VIRTIO_MSG_BUS_DEVICE_CLASS(klass);
+
+    bdc->process = virtio_msg_bus_xen_process;
+    bdc->send = virtio_msg_bus_xen_send;
+
+    device_class_set_parent_realize(dc, virtio_msg_bus_xen_realize,
+                                    &bdc->parent_realize);
+    device_class_set_parent_unrealize(dc, virtio_msg_bus_xen_unrealize,
+                                      &bdc->parent_unrealize);
+    device_class_set_props(dc, virtio_msg_bus_xen_props);
+}
+
+static const TypeInfo virtio_msg_bus_xen_info = {
+    .name = TYPE_VIRTIO_MSG_BUS_XEN,
+    .parent = TYPE_VIRTIO_MSG_BUS_DEVICE,
+    .instance_size = sizeof(VirtIOMSGBusXen),
+    .class_init = virtio_msg_bus_xen_class_init,
+};
+
+static void virtio_msg_bus_xen_register_types(void)
+{
+    type_register_static(&virtio_msg_bus_xen_info);
+}
+
+type_init(virtio_msg_bus_xen_register_types)
diff --git a/include/hw/virtio/pagemap.h b/include/hw/virtio/pagemap.h
new file mode 100644
index 0000000000..9298b4864a
--- /dev/null
+++ b/include/hw/virtio/pagemap.h
@@ -0,0 +1,100 @@
+/*
+ * Linux user-space virt to phys mapping.
+ *
+ * SPDX-License-Identifier: GPL-2.0-only
+ */
+#ifndef PAGEMAP_H_
+#define PAGEMAP_H_
+
+#include <assert.h>
+#include <inttypes.h>
+#include <stdint.h>
+#include <stdio.h>
+#include <stdlib.h>
+
+#include <fcntl.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+
+/*
+ * From https://www.kernel.org/doc/Documentation/admin-guide/mm/pagemap.rst
+ *
+ * ``/proc/pid/pagemap``.  This file lets a userspace process find out which
+ * physical frame each virtual page is mapped to.  It contains one 64-bit
+ * value for each virtual page, containing the following data (from
+ * ``fs/proc/task_mmu.c``, above pagemap_read):
+ *
+ *  * Bits 0-54  page frame number (PFN) if present
+ *  * Bits 0-4   swap type if swapped
+ *  * Bits 5-54  swap offset if swapped
+ *  * Bit  55    pte is soft-dirty (see
+ *    :ref:`Documentation/admin-guide/mm/soft-dirty.rst <soft_dirty>`)
+ *  * Bit  56    page exclusively mapped (since 4.2)
+ *  * Bit  57    pte is uffd-wp write-protected (since 5.13) (see
+ *    :ref:`Documentation/admin-guide/mm/userfaultfd.rst <userfaultfd>`)
+ *  * Bits 58-60 zero
+ *  * Bit  61    page is file-page or shared-anon (since 3.5)
+ *  * Bit  62    page swapped
+ *  * Bit  63    page present
+ */
+
+#define PAGEMAP_PFN_MASK ((1ULL << 55) - 1)
+#define PAGEMAP_PAGE_PRESENT (1ULL << 63)
+#define PAGEMAP_FAILED (~0ULL)
+
+static inline int pagemap_open_self(void)
+{
+    int r;
+
+    r = open("/proc/self/pagemap", O_RDONLY);
+    if (r < 0) {
+        perror("open");
+    }
+    return r;
+}
+
+static inline uint64_t pagemap_virt_to_phys_fd(int fd, void *ptr)
+{
+    uint64_t va = (uintptr_t)ptr;
+    uint64_t pagemap;
+    uint64_t offset;
+    uint64_t vfn;
+    uint64_t pa;
+    int pagesize;
+    ssize_t r;
+
+    pagesize = qemu_real_host_page_size();
+    offset = va % pagesize;
+    vfn = va / pagesize;
+    r = pread(fd, &pagemap, sizeof pagemap, 8 * vfn);
+    assert(r == sizeof pagemap);
+
+    if (!(pagemap & PAGEMAP_PAGE_PRESENT)) {
+        return PAGEMAP_FAILED;
+    }
+
+    pa = (pagemap & PAGEMAP_PFN_MASK) * pagesize;
+    if (!pa) {
+        return PAGEMAP_FAILED;
+    }
+
+    pa |= offset;
+    return pa;
+}
+
+static inline uint64_t pagemap_virt_to_phys(void *ptr)
+{
+    uint64_t pa;
+    int fd;
+
+    fd = pagemap_open_self();
+    if (fd < 0) {
+        return PAGEMAP_FAILED;
+    }
+
+    pa = pagemap_virt_to_phys_fd(fd, ptr);
+    close(fd);
+    return pa;
+}
+#endif
diff --git a/include/hw/virtio/spsc_queue.h b/include/hw/virtio/spsc_queue.h
new file mode 100644
index 0000000000..796008da08
--- /dev/null
+++ b/include/hw/virtio/spsc_queue.h
@@ -0,0 +1,213 @@
+/*
+ * Hardened and lockless Single Producer Single Consumer Queue implemented
+ * over shared-memory.
+ *
+ * The queue implementation does not look at packet contents, it's up to upper
+ * layers to make sure data is produced and parsed safely. All data is copied
+ * in/out from/to local private buffers so the peer cannot mess with them while
+ * upper layers parse.
+ *
+ * The queue is split into a private and a shared part.
+ * The private part contains cached and sanitized versions of the indexes that
+ * indicate our position in the ring-buffer. Peers can corrupt the shared area
+ * but have no access to the private area. So whenever we copy from the shared
+ * area into the private one, we need to sanitize indexes and make sure they
+ * are within bounds.
+ *
+ * A malicious peer can send corrupt data, it can stop receiving or flood the
+ * queue causing a sort of denial of service but it can NOT cause our side
+ * to copy data in or out of buffers outside of the shared memory area.
+ *
+ * This implementation expects the SHM area to be cache-coherent or uncached.
+ * The shared area can be mapped in different ways and our peer may be anything
+ * from another thread on our same OS to an FPGA implementation on a PCI card.
+ * So local CPU cache-lines sizes, or spin-locks and things that work on a
+ * single CPU cluster are not used. Instead the implementation sticks to atomic
+ * load/stores of 32b values and to using memory-barriers to guarantee ordering.
+ *
+ * SPDX-License-Identifier: GPL-2.0-only
+ */
+
+#ifndef SPSC_QUEUE_H__
+#define SPSC_QUEUE_H__
+
+#include <assert.h>
+#include "qemu/atomic.h"
+
+#define BUG_ON(x) assert(!(x))
+
+#define SPSC_QUEUE_MAX_PACKET_SIZE 64
+/*
+ * This cache-line size is used to align fields in the hope of
+ * avoiding cache-line ping-pong:ing. Since the queue layout is
+ * used across heterogenous CPU clusters and across FPGA/HW implementations,
+ * a fixed size must be used, i.e not the local CPU's cache-line size.
+ */
+#define SPSC_QUEUE_CACHE_LINE_SIZE 64
+
+typedef struct spsc_queue_shared {
+    uint32_t head __attribute__((__aligned__(SPSC_QUEUE_CACHE_LINE_SIZE)));
+    uint32_t tail __attribute__((__aligned__(SPSC_QUEUE_CACHE_LINE_SIZE)));
+    uint32_t packets[][SPSC_QUEUE_MAX_PACKET_SIZE / 4]
+        __attribute__((__aligned__(SPSC_QUEUE_CACHE_LINE_SIZE)));
+} spsc_queue_shared;
+
+typedef struct spsc_queue {
+    uint32_t cached_tail;
+    uint32_t cached_head;
+    spsc_queue_shared *shm;
+    const char *name;
+    unsigned int capacity;
+} spsc_queue;
+
+/* Atomically load and sanitize an index from the SHM area.  */
+static inline uint32_t spsc_atomic_load(spsc_queue *q, uint32_t *ptr)
+{
+    uint32_t val;
+
+    val = qatomic_read(ptr);
+    /* Make sure packet reads are done after reading the index.  */
+    smp_mb_acquire();
+
+    /* Bounds check that index is within queue size.  */
+    if (val >= q->capacity) {
+        val = val % q->capacity;
+    }
+
+    return val;
+}
+
+static inline void spsc_atomic_store(spsc_queue *q, uint32_t *ptr, uint32_t v)
+{
+    /* Make sure packet-data gets written before updating the index.  */
+    smp_mb_release();
+    qatomic_set(ptr, v);
+}
+
+/* Returns the capacity of a queue given a specific mapsize. */
+static inline unsigned int spsc_capacity(size_t mapsize)
+{
+    unsigned int capacity;
+    spsc_queue *q = NULL;
+
+    if (mapsize < sizeof(*q->shm)) {
+        return 0;
+    }
+
+    /* Start with the size of the shared area. */
+    mapsize -= sizeof(*q->shm);
+    capacity = mapsize / sizeof(q->shm->packets[0]);
+
+    if (capacity < 2) {
+        /* Capacities of less than 2 are invalid. */
+        return 0;
+    }
+
+    return capacity;
+}
+
+static inline size_t spsc_mapsize(unsigned int capacity)
+{
+    spsc_queue *q = NULL;
+    size_t mapsize;
+
+    BUG_ON(capacity < 2);
+
+    mapsize = sizeof(*q->shm);
+    mapsize += sizeof(q->shm->packets[0]) * capacity;
+
+    return mapsize;
+}
+
+static inline void spsc_init(spsc_queue *q, const char *name, size_t capacity,
+                             void *mem)
+{
+    BUG_ON(!mem);
+
+    /* Initialize private queue area to all zeroes */
+    memset(q, 0, sizeof *q);
+
+    q->shm = (spsc_queue_shared *) mem;
+    q->name = name;
+    q->capacity = capacity;
+
+    /* In case we're opening a pre-existing queue, pick up where we left off. */
+    q->cached_tail = spsc_atomic_load(q, &q->shm->tail);
+    q->cached_head = spsc_atomic_load(q, &q->shm->head);
+}
+
+static inline bool spsc_queue_is_full(spsc_queue *q)
+{
+    uint32_t next_head;
+    uint32_t head;
+
+    head = spsc_atomic_load(q, &q->shm->head);
+
+    next_head = head + 1;
+    if (next_head >= q->capacity) {
+        next_head = 0;
+    }
+
+    if (next_head == q->cached_tail) {
+        q->cached_tail = spsc_atomic_load(q, &q->shm->tail);
+        if (next_head == q->cached_tail) {
+            return true;
+        }
+    }
+    return false;
+}
+
+static inline bool spsc_send(spsc_queue *q, void *buf, size_t size)
+{
+    uint32_t next_head;
+    uint32_t head;
+
+    BUG_ON(size > sizeof q->shm->packets[0]);
+    BUG_ON(size == 0);
+
+    /* Is the queue full?  */
+    if (spsc_queue_is_full(q)) {
+        return false;
+    }
+
+    head = spsc_atomic_load(q, &q->shm->head);
+    next_head = head + 1;
+    if (next_head >= q->capacity) {
+        next_head = 0;
+    }
+
+    memcpy(q->shm->packets[head], buf, size);
+
+    spsc_atomic_store(q, &q->shm->head, next_head);
+    return true;
+}
+
+static inline bool spsc_recv(spsc_queue *q, void *buf, size_t size)
+{
+    uint32_t tail;
+
+    BUG_ON(size > sizeof q->shm->packets[0]);
+    BUG_ON(size == 0);
+
+    tail = spsc_atomic_load(q, &q->shm->tail);
+
+    /* Is the queue empty?  */
+    if (tail == q->cached_head) {
+        q->cached_head = spsc_atomic_load(q, &q->shm->head);
+        if (tail == q->cached_head) {
+            return false;
+        }
+    }
+
+    memcpy(buf, q->shm->packets[tail], size);
+
+    /* Update the read pointer.  */
+    tail++;
+    if (tail >= q->capacity) {
+        tail = 0;
+    }
+
+    spsc_atomic_store(q, &q->shm->tail, tail);
+    return true;
+}
+#endif /* SPSC_QUEUE_H__ */
diff --git a/include/hw/virtio/virtio-msg-bus-xen.h b/include/hw/virtio/virtio-msg-bus-xen.h
new file mode 100644
index 0000000000..a4627f6e59
--- /dev/null
+++ b/include/hw/virtio/virtio-msg-bus-xen.h
@@ -0,0 +1,48 @@
+/*
+ * VirtIO MSG bus on top of Xen.
+ *
+ * Copyright (c) 2024 Advanced Micro Devices, Inc.
+ * Written by Edgar E. Iglesias <edgar.iglesias@amd.com>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#ifndef QEMU_VIRTIO_MSG_BUS_XEN_H
+#define QEMU_VIRTIO_MSG_BUS_XEN_H
+
+#include "qom/object.h"
+#include "chardev/char.h"
+#include "chardev/char-fe.h"
+#include "sysemu/hostmem.h"
+#include "hw/virtio/virtio-msg-bus.h"
+#include "hw/virtio/spsc_queue.h"
+
+#define TYPE_VIRTIO_MSG_BUS_XEN "virtio-msg-bus-xen"
+OBJECT_DECLARE_SIMPLE_TYPE(VirtIOMSGBusXen, VIRTIO_MSG_BUS_XEN)
+#define VIRTIO_MSG_BUS_XEN_GET_PARENT_CLASS(obj) \
+        OBJECT_GET_PARENT_CLASS(obj, TYPE_VIRTIO_MSG_BUS_XEN)
+
+typedef struct VirtIOMSGBusXen {
+    VirtIOMSGBusDevice parent;
+
+    struct {
+        xenevtchn_handle *eh;
+
+        char *shm;
+        uint16_t port;
+        evtchn_port_t local_port;
+    } xen;
+
+    struct {
+        spsc_queue driver;
+        spsc_queue device;
+    } shm_queues;
+
+    struct {
+        uint64_t shm_base;
+        uint64_t shm_gnt_ref;
+        uint32_t bus_id;
+        uint16_t dev_num;
+    } cfg;
+} VirtIOMSGBusXen;
+#endif
-- 
2.34.1

